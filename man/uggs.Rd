% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/uggs.R
\name{uggs}
\alias{uggs}
\title{Nonparametric bias-corrected and accelerated bootstrap confidence
  limits}
\usage{
uggs(df, B, est, ..., jcount = nrow(df), jreps = 5, iereps = 2,
  J = 10, alpha = c(0.025, 0.05, 0.1), progress = TRUE,
  num_workers = 4, ie_calc = FALSE)
}
\arguments{
\item{df}{a dataframe with \eqn{n} rows, assumed to be independently sampled 
from the target population.}

\item{B}{number of bootstrap replications}

\item{est}{function of the estimating equation, \eqn{\hat{\theta} = est(x)}, 
which returns a real value for the parameter of interest}

\item{...}{additional arguments for est}

\item{jcount}{value used in calculating a. Because n can get very large, 
calculating \eqn{n} jackknife values can be slow. A way to speed up the 
calculation is to collect the \eqn{n} observations into \eqn{jcount} 
groups and deleting each group in turn. Thus we only 
evaluate \eqn{jcount} calculations instead of \eqn{n}.}

\item{jreps}{number of repetitions of grouped jackknives. These \eqn{jreps}
calculations are averaged to obtain our \eqn{\hat{a}}.}

\item{iereps}{a separate jackknife calculation estimates the 
internal standard error. The \eqn{B}-length vector \eqn{theta^*} is 
   randomly grouped into \eqn{J} groups, and each group is deleted in turn
   to recompute our estimates. This is done \eqn{iereps} times and 
   averaged to compute the final jackknife estimates.}

\item{J}{the number of groups \eqn{B}-length vector \eqn{theta^*} is 
partitioned into to calculate internal standard error}

\item{alpha}{percentiles to be computed for the confidence limits. Providing
alpha values below 0.5 is sufficient; upper limits are automatically 
computed}

\item{progress}{logical for a progress bar in bootstrap calculations}

\item{num_workers}{the number of workers used for parallel processing}
}
\value{
\itemize{
\item limits: four columns housing information on confidence limits
\itemize{	
   \item `bca` shows the empirical bca confidence limits
		at the alpha percentiles
   \item `std` shows the the standard confidence limits, 
     \eqn{\hat{\theta} + \hat{\sigma}z_{\alpha}}
   \item `pct` gives the percentiles of the sorted B bootstrap replications 
     that correspond to `bca`
   \item `pct`, gives the percentiles of the ordered B bootstrap replications
     corresponding to the bca limits
   \item `jacksd` is internal standard errors for the bca limits
}
\item stats: top line of stats shows 5 estimates, and bottom line gives the 
		internal standard errors for the five quantities below:
\itemize{
   \item theta: \eqn{f(x)}, original point estimate of the parameter of
    interest
	  \item `sdboot` is the bootstrap estimate of standard error;
	  \item `z0` is the bca bias correction value, in this case quite
    negative
	  \item `a` is the _acceleration_, a component of the bca
    limits (nearly zero here)
	  \item `sdjack` is the jackknife estimate
    of standard error for theta. 
}
\item B.mean: bootstrap sample size B, and the mean of the B
    bootstrap replications \eqn{\hat{\theta^*}}

\item ustats: The bias-corrected estimator `2 * t0 - mean(tt)`,
    and an estimate, `sdu`, of its sampling error
}
}
\description{
This routine computes nonparametric confidence limits for
  bootstrap estimates.
}
\details{
Bootstrap confidence limits correct the standard method of confidence 
intervals in three ways:

\enumerate{
\item param the bootstrap cdf, \eqn{G}
\item the bias-correction number \eqn{z_{0}} 
\item the acceleration number \eqn{a} that measures the rate of change in 
  \eqn{\sigma_{t_0}} as the data changes.
}
}
\examples{
library(lfe)
library(uggs)

## create covariates
x1 <- rnorm(1000)
x2 <- rnorm(length(x1))

## fixed effects
fe <- factor(sample(20, length(x1), replace=TRUE))

## effects for fe
fe_effs <- rnorm(nlevels(fe))

## creating left hand side y
u <- rnorm(length(x1))
y <- 2 * x1 + x2 + fe_effs[fe] + u

# create dataframe to pass into uggs
df_test <- as.data.frame(cbind(y, x1, x2, fe))

# function that returns parameter of interest, x1
est_test <- function(df){
	m <- felm(y ~ x1 + x2 | fe, df)
	as.numeric(coef(m)["x1"])
}

x1_boot <- uggs(df_test, 1000, est_test, jcount = 40, jreps = 5)

}
\references{
Efron, Bradley, and Trevor J. Hastie. Computer Age Statistical 
		Inference: Algorithms, Evidence, and Data Science. Cambridge University 
		Press, 2017.

Efron, Brad, and Balasubramanian Narasimhan. The Automatic 
		Construction of Bootstrap Confidence Intervals. 2018.
}
